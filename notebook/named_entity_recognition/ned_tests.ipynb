{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fuzzywuzzy\n",
      "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
      "Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
      "Installing collected packages: fuzzywuzzy\n",
      "Successfully installed fuzzywuzzy-0.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Example Workflow with Fuzzy Matching + NER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of project names\n",
    "projects = [\n",
    "    \"Projekt Mozart II\",\n",
    "    \"Projekt Mozart I\",\n",
    "    \"The Five\",\n",
    "    \"DFI Zukunftspark Oberfranken IV\",\n",
    "    \"Berliner Flair in Friedrichshain II\",\n",
    "    \"DFI Zukunftspark Oberfranken V\",\n",
    "    \"DFI Zukunftspark Oberfranken III\",\n",
    "    \"Am Akkonplatz\",\n",
    "    \"Berliner Flair in Friedrichshain\",\n",
    "    \"Projekt Mozart III\",    \n",
    "    \"Tonhallen-Passage II\"\n",
    "]\n",
    "\n",
    "projects = sorted(projects, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess the email text\n",
    "def preprocess_email(email):\n",
    "    # Lowercase the text to ensure case-insensitive matching\n",
    "    email = email.lower()\n",
    "    # Optional: You can add more cleaning steps if necessary (e.g., removing greetings, signatures)\n",
    "\n",
    "    return email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Function to extract project names from an email\n",
    "def extract_project_names(email, projects):\n",
    "    result = []\n",
    "    email = preprocess_email(email)\n",
    "\n",
    "    # Load the German NER model from Hugging Face\n",
    "    ner = pipeline(\"ner\", model=\"deepset/gbert-base\")\n",
    "\n",
    "    # Step 1: Exact string matching\n",
    "    exact_matches = [project for project in projects if project.lower() in email]\n",
    "\n",
    "    if exact_matches:\n",
    "        project_name = exact_matches[0]\n",
    "        confidence = 100\n",
    "\n",
    "        result.append({project_name: project_name, confidence: confidence})\n",
    "        return result\n",
    "        \n",
    "\n",
    "    # Step 2: NER to detect project-like entities (if exact matches fail)\n",
    "    entities = ner(email)\n",
    "    ner_matches = [\n",
    "        (entity['word'], entity['score'])\n",
    "        for entity in entities if any(proj.lower() in entity['word'].lower() for proj in projects)\n",
    "        #and entity['score'] > 0.1  # Filter based on confidence threshold\n",
    "    ]\n",
    "\n",
    "    # Step 3: Fuzzy matching (fallback if exact and NER fail)\n",
    "    if not exact_matches:\n",
    "        fuzzy_match, confidence = process.extractOne(email, projects)\n",
    "        fuzzy_matches = [fuzzy_match] if confidence > 70 else []  # Only accept if confidence is reasonably high\n",
    "    else:\n",
    "        fuzzy_matches = []\n",
    "\n",
    "    # Combine the results\n",
    "    combined_matches = list(set(exact_matches + ner_matches + fuzzy_matches))\n",
    "\n",
    "    return combined_matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/jovyan/.local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Project Names: ['DFI Zukunftspark Oberfranken III']\n"
     ]
    }
   ],
   "source": [
    "# Example: User email in German\n",
    "\n",
    "# DFI Park Oberfranken V. \n",
    "# Projekt Musik III\n",
    "email = (\n",
    "    \"Hallo, \"\n",
    "    \"ich habe eine Frage zu den Zinsen für das Projekt Musik III. \"\n",
    "    \"Könnten Sie mir bitte den aktuellen Zinssatz nennen? \"\n",
    "    \"Vielen Dank und viele Grüße, \"\n",
    "    \"Max Mustermann\"\n",
    ")\n",
    "\n",
    "# Extract project names\n",
    "project_names = extract_project_names(email, projects)\n",
    "\n",
    "print(f\"Extracted Project Names: {project_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tonhallen-Passage II', 'The Five', 'Projekt Mozart III', 'Projekt Mozart II', 'Projekt Mozart I', 'DFI Zukunftspark Oberfranken VI', 'DFI Zukunftspark Oberfranken V', 'DFI Zukunftspark Oberfranken IV', 'Berliner Flair in Friedrichshain II', 'Berliner Flair in Friedrichshain', 'Am Akkonplatz']\n",
      "Entities found: [{'entity': 'LABEL_1', 'score': np.float32(0.8397179), 'index': 1, 'word': 'Hallo', 'start': 0, 'end': 5}, {'entity': 'LABEL_1', 'score': np.float32(0.7619211), 'index': 2, 'word': ',', 'start': 5, 'end': 6}, {'entity': 'LABEL_1', 'score': np.float32(0.8200022), 'index': 3, 'word': 'ich', 'start': 7, 'end': 10}, {'entity': 'LABEL_1', 'score': np.float32(0.8509396), 'index': 4, 'word': 'habe', 'start': 11, 'end': 15}, {'entity': 'LABEL_1', 'score': np.float32(0.79300916), 'index': 5, 'word': 'eine', 'start': 16, 'end': 20}, {'entity': 'LABEL_1', 'score': np.float32(0.6879423), 'index': 6, 'word': 'Frage', 'start': 21, 'end': 26}, {'entity': 'LABEL_1', 'score': np.float32(0.692166), 'index': 7, 'word': 'zu', 'start': 27, 'end': 29}, {'entity': 'LABEL_0', 'score': np.float32(0.61512524), 'index': 8, 'word': 'den', 'start': 30, 'end': 33}, {'entity': 'LABEL_0', 'score': np.float32(0.59935653), 'index': 9, 'word': 'Zinsen', 'start': 34, 'end': 40}, {'entity': 'LABEL_1', 'score': np.float32(0.5599741), 'index': 10, 'word': 'für', 'start': 41, 'end': 44}, {'entity': 'LABEL_1', 'score': np.float32(0.6325242), 'index': 11, 'word': 'das', 'start': 45, 'end': 48}, {'entity': 'LABEL_1', 'score': np.float32(0.68960565), 'index': 12, 'word': 'Projekt', 'start': 49, 'end': 56}, {'entity': 'LABEL_1', 'score': np.float32(0.7499216), 'index': 13, 'word': 'X', 'start': 57, 'end': 58}, {'entity': 'LABEL_1', 'score': np.float32(0.5258455), 'index': 14, 'word': '##K', 'start': 58, 'end': 59}, {'entity': 'LABEL_1', 'score': np.float32(0.62778354), 'index': 15, 'word': '##ön', 'start': 59, 'end': 61}, {'entity': 'LABEL_0', 'score': np.float32(0.5522141), 'index': 16, 'word': '##nten', 'start': 61, 'end': 65}, {'entity': 'LABEL_1', 'score': np.float32(0.75291014), 'index': 17, 'word': 'Sie', 'start': 66, 'end': 69}, {'entity': 'LABEL_1', 'score': np.float32(0.6520041), 'index': 18, 'word': 'mir', 'start': 70, 'end': 73}, {'entity': 'LABEL_1', 'score': np.float32(0.6536701), 'index': 19, 'word': 'bitte', 'start': 74, 'end': 79}, {'entity': 'LABEL_1', 'score': np.float32(0.59190774), 'index': 20, 'word': 'den', 'start': 80, 'end': 83}, {'entity': 'LABEL_1', 'score': np.float32(0.53641117), 'index': 21, 'word': 'aktuellen', 'start': 84, 'end': 93}, {'entity': 'LABEL_1', 'score': np.float32(0.60822845), 'index': 22, 'word': 'Zinss', 'start': 94, 'end': 99}, {'entity': 'LABEL_1', 'score': np.float32(0.75823593), 'index': 23, 'word': '##atz', 'start': 99, 'end': 102}, {'entity': 'LABEL_1', 'score': np.float32(0.8268305), 'index': 24, 'word': 'nennen', 'start': 103, 'end': 109}, {'entity': 'LABEL_1', 'score': np.float32(0.5688957), 'index': 25, 'word': '?', 'start': 109, 'end': 110}, {'entity': 'LABEL_1', 'score': np.float32(0.6868283), 'index': 26, 'word': 'Vielen', 'start': 111, 'end': 117}, {'entity': 'LABEL_1', 'score': np.float32(0.7897066), 'index': 27, 'word': 'Dank', 'start': 118, 'end': 122}, {'entity': 'LABEL_0', 'score': np.float32(0.50101084), 'index': 28, 'word': 'und', 'start': 123, 'end': 126}, {'entity': 'LABEL_1', 'score': np.float32(0.69650275), 'index': 29, 'word': 'viele', 'start': 127, 'end': 132}, {'entity': 'LABEL_1', 'score': np.float32(0.78236514), 'index': 30, 'word': 'Grü', 'start': 133, 'end': 136}, {'entity': 'LABEL_1', 'score': np.float32(0.77407515), 'index': 31, 'word': '##ße', 'start': 136, 'end': 138}, {'entity': 'LABEL_0', 'score': np.float32(0.51873803), 'index': 32, 'word': ',', 'start': 138, 'end': 139}, {'entity': 'LABEL_0', 'score': np.float32(0.7665654), 'index': 33, 'word': 'Max', 'start': 140, 'end': 143}, {'entity': 'LABEL_1', 'score': np.float32(0.71471614), 'index': 34, 'word': 'Muster', 'start': 144, 'end': 150}, {'entity': 'LABEL_1', 'score': np.float32(0.8482466), 'index': 35, 'word': '##mann', 'start': 150, 'end': 154}, {'entity': 'LABEL_1', 'score': np.float32(0.8074707), 'index': 36, 'word': '##Ha', 'start': 154, 'end': 156}, {'entity': 'LABEL_1', 'score': np.float32(0.8862558), 'index': 37, 'word': '##llo', 'start': 156, 'end': 159}, {'entity': 'LABEL_1', 'score': np.float32(0.7341731), 'index': 38, 'word': ',', 'start': 159, 'end': 160}, {'entity': 'LABEL_1', 'score': np.float32(0.8282306), 'index': 39, 'word': 'ich', 'start': 161, 'end': 164}, {'entity': 'LABEL_1', 'score': np.float32(0.87298983), 'index': 40, 'word': 'habe', 'start': 165, 'end': 169}, {'entity': 'LABEL_1', 'score': np.float32(0.7947959), 'index': 41, 'word': 'eine', 'start': 170, 'end': 174}, {'entity': 'LABEL_1', 'score': np.float32(0.7101119), 'index': 42, 'word': 'Frage', 'start': 175, 'end': 180}, {'entity': 'LABEL_1', 'score': np.float32(0.7028425), 'index': 43, 'word': 'zu', 'start': 181, 'end': 183}, {'entity': 'LABEL_0', 'score': np.float32(0.61937606), 'index': 44, 'word': 'den', 'start': 184, 'end': 187}, {'entity': 'LABEL_0', 'score': np.float32(0.6176015), 'index': 45, 'word': 'Zinsen', 'start': 188, 'end': 194}, {'entity': 'LABEL_1', 'score': np.float32(0.5882704), 'index': 46, 'word': 'für', 'start': 195, 'end': 198}, {'entity': 'LABEL_1', 'score': np.float32(0.6463719), 'index': 47, 'word': 'das', 'start': 199, 'end': 202}, {'entity': 'LABEL_1', 'score': np.float32(0.6841625), 'index': 48, 'word': 'Projekt', 'start': 203, 'end': 210}, {'entity': 'LABEL_1', 'score': np.float32(0.75203425), 'index': 49, 'word': 'Y', 'start': 211, 'end': 212}, {'entity': 'LABEL_1', 'score': np.float32(0.66831076), 'index': 50, 'word': '.', 'start': 212, 'end': 213}, {'entity': 'LABEL_1', 'score': np.float32(0.6342865), 'index': 51, 'word': 'Könnte', 'start': 214, 'end': 220}, {'entity': 'LABEL_1', 'score': np.float32(0.59312046), 'index': 52, 'word': '##n', 'start': 220, 'end': 221}, {'entity': 'LABEL_1', 'score': np.float32(0.83220816), 'index': 53, 'word': 'Sie', 'start': 222, 'end': 225}, {'entity': 'LABEL_1', 'score': np.float32(0.6326587), 'index': 54, 'word': 'mir', 'start': 226, 'end': 229}, {'entity': 'LABEL_1', 'score': np.float32(0.73478526), 'index': 55, 'word': 'bitte', 'start': 230, 'end': 235}, {'entity': 'LABEL_1', 'score': np.float32(0.645084), 'index': 56, 'word': 'den', 'start': 236, 'end': 239}, {'entity': 'LABEL_1', 'score': np.float32(0.56418836), 'index': 57, 'word': 'aktuellen', 'start': 240, 'end': 249}, {'entity': 'LABEL_1', 'score': np.float32(0.63321924), 'index': 58, 'word': 'Zinss', 'start': 250, 'end': 255}, {'entity': 'LABEL_1', 'score': np.float32(0.7850941), 'index': 59, 'word': '##atz', 'start': 255, 'end': 258}, {'entity': 'LABEL_1', 'score': np.float32(0.8392892), 'index': 60, 'word': 'nennen', 'start': 259, 'end': 265}, {'entity': 'LABEL_1', 'score': np.float32(0.67921066), 'index': 61, 'word': '?', 'start': 265, 'end': 266}, {'entity': 'LABEL_1', 'score': np.float32(0.7448517), 'index': 62, 'word': 'Vielen', 'start': 267, 'end': 273}, {'entity': 'LABEL_1', 'score': np.float32(0.8402983), 'index': 63, 'word': 'Dank', 'start': 274, 'end': 278}, {'entity': 'LABEL_1', 'score': np.float32(0.55959994), 'index': 64, 'word': 'und', 'start': 279, 'end': 282}, {'entity': 'LABEL_1', 'score': np.float32(0.7583752), 'index': 65, 'word': 'viele', 'start': 283, 'end': 288}, {'entity': 'LABEL_1', 'score': np.float32(0.8366019), 'index': 66, 'word': 'Grü', 'start': 289, 'end': 292}, {'entity': 'LABEL_1', 'score': np.float32(0.8274419), 'index': 67, 'word': '##ße', 'start': 292, 'end': 294}, {'entity': 'LABEL_1', 'score': np.float32(0.54230523), 'index': 68, 'word': ',', 'start': 294, 'end': 295}, {'entity': 'LABEL_0', 'score': np.float32(0.74227417), 'index': 69, 'word': 'Max', 'start': 296, 'end': 299}, {'entity': 'LABEL_1', 'score': np.float32(0.7469489), 'index': 70, 'word': 'Muster', 'start': 300, 'end': 306}, {'entity': 'LABEL_1', 'score': np.float32(0.86169505), 'index': 71, 'word': '##mann', 'start': 306, 'end': 310}, {'entity': 'LABEL_1', 'score': np.float32(0.7866566), 'index': 72, 'word': '##Ha', 'start': 310, 'end': 312}, {'entity': 'LABEL_1', 'score': np.float32(0.8846493), 'index': 73, 'word': '##llo', 'start': 312, 'end': 315}, {'entity': 'LABEL_1', 'score': np.float32(0.738502), 'index': 74, 'word': ',', 'start': 315, 'end': 316}, {'entity': 'LABEL_1', 'score': np.float32(0.81847435), 'index': 75, 'word': 'ich', 'start': 317, 'end': 320}, {'entity': 'LABEL_1', 'score': np.float32(0.86453474), 'index': 76, 'word': 'habe', 'start': 321, 'end': 325}, {'entity': 'LABEL_1', 'score': np.float32(0.7827812), 'index': 77, 'word': 'eine', 'start': 326, 'end': 330}, {'entity': 'LABEL_1', 'score': np.float32(0.68198216), 'index': 78, 'word': 'Frage', 'start': 331, 'end': 336}, {'entity': 'LABEL_1', 'score': np.float32(0.6738606), 'index': 79, 'word': 'zu', 'start': 337, 'end': 339}, {'entity': 'LABEL_0', 'score': np.float32(0.6245059), 'index': 80, 'word': 'den', 'start': 340, 'end': 343}, {'entity': 'LABEL_0', 'score': np.float32(0.62127835), 'index': 81, 'word': 'Zinsen', 'start': 344, 'end': 350}, {'entity': 'LABEL_1', 'score': np.float32(0.55686855), 'index': 82, 'word': 'für', 'start': 351, 'end': 354}, {'entity': 'LABEL_1', 'score': np.float32(0.64855576), 'index': 83, 'word': 'das', 'start': 355, 'end': 358}, {'entity': 'LABEL_1', 'score': np.float32(0.51040244), 'index': 84, 'word': 'DF', 'start': 359, 'end': 361}, {'entity': 'LABEL_0', 'score': np.float32(0.5633122), 'index': 85, 'word': '##I', 'start': 361, 'end': 362}, {'entity': 'LABEL_1', 'score': np.float32(0.57168233), 'index': 86, 'word': 'Zukunfts', 'start': 363, 'end': 371}, {'entity': 'LABEL_0', 'score': np.float32(0.5182595), 'index': 87, 'word': '##park', 'start': 371, 'end': 375}, {'entity': 'LABEL_1', 'score': np.float32(0.6618846), 'index': 88, 'word': 'Ober', 'start': 376, 'end': 380}, {'entity': 'LABEL_0', 'score': np.float32(0.5339827), 'index': 89, 'word': '##franken', 'start': 380, 'end': 387}, {'entity': 'LABEL_1', 'score': np.float32(0.6686801), 'index': 90, 'word': 'VI', 'start': 388, 'end': 390}, {'entity': 'LABEL_1', 'score': np.float32(0.7161862), 'index': 91, 'word': '.', 'start': 390, 'end': 391}, {'entity': 'LABEL_1', 'score': np.float32(0.63611716), 'index': 92, 'word': 'Könnte', 'start': 392, 'end': 398}, {'entity': 'LABEL_1', 'score': np.float32(0.5859095), 'index': 93, 'word': '##n', 'start': 398, 'end': 399}, {'entity': 'LABEL_1', 'score': np.float32(0.810403), 'index': 94, 'word': 'Sie', 'start': 400, 'end': 403}, {'entity': 'LABEL_1', 'score': np.float32(0.6246493), 'index': 95, 'word': 'mir', 'start': 404, 'end': 407}, {'entity': 'LABEL_1', 'score': np.float32(0.6825495), 'index': 96, 'word': 'bitte', 'start': 408, 'end': 413}, {'entity': 'LABEL_1', 'score': np.float32(0.6130089), 'index': 97, 'word': 'den', 'start': 414, 'end': 417}, {'entity': 'LABEL_1', 'score': np.float32(0.54284996), 'index': 98, 'word': 'aktuellen', 'start': 418, 'end': 427}, {'entity': 'LABEL_1', 'score': np.float32(0.62118995), 'index': 99, 'word': 'Zinss', 'start': 428, 'end': 433}, {'entity': 'LABEL_1', 'score': np.float32(0.7676253), 'index': 100, 'word': '##atz', 'start': 433, 'end': 436}, {'entity': 'LABEL_1', 'score': np.float32(0.8154433), 'index': 101, 'word': 'nennen', 'start': 437, 'end': 443}, {'entity': 'LABEL_1', 'score': np.float32(0.6067264), 'index': 102, 'word': '?', 'start': 443, 'end': 444}, {'entity': 'LABEL_1', 'score': np.float32(0.7020315), 'index': 103, 'word': 'Vielen', 'start': 445, 'end': 451}, {'entity': 'LABEL_1', 'score': np.float32(0.7894767), 'index': 104, 'word': 'Dank', 'start': 452, 'end': 456}, {'entity': 'LABEL_0', 'score': np.float32(0.51965594), 'index': 105, 'word': 'und', 'start': 457, 'end': 460}, {'entity': 'LABEL_1', 'score': np.float32(0.6485933), 'index': 106, 'word': 'viele', 'start': 461, 'end': 466}, {'entity': 'LABEL_1', 'score': np.float32(0.7320605), 'index': 107, 'word': 'Grü', 'start': 467, 'end': 470}, {'entity': 'LABEL_1', 'score': np.float32(0.71751934), 'index': 108, 'word': '##ße', 'start': 470, 'end': 472}, {'entity': 'LABEL_0', 'score': np.float32(0.5740351), 'index': 109, 'word': ',', 'start': 472, 'end': 473}, {'entity': 'LABEL_0', 'score': np.float32(0.765239), 'index': 110, 'word': 'Max', 'start': 474, 'end': 477}, {'entity': 'LABEL_1', 'score': np.float32(0.63467264), 'index': 111, 'word': 'Muster', 'start': 478, 'end': 484}, {'entity': 'LABEL_1', 'score': np.float32(0.76271826), 'index': 112, 'word': '##mann', 'start': 484, 'end': 488}]\n",
      "Fuzzy Matched Project: DFI Zukunftspark Oberfranken VI with confidence: 100\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Load the German NER model from Hugging Face\n",
    "ner = pipeline(\"ner\", model=\"deepset/gbert-base\")\n",
    "\n",
    "# List of project names\n",
    "projects = [\n",
    "    \"Projekt Mozart II\",\n",
    "    \"Projekt Mozart I\",\n",
    "    \"The Five\",\n",
    "    \"Berliner Flair in Friedrichshain II\",\n",
    "    \"DFI Zukunftspark Oberfranken V\",\n",
    "    \"Projekt Mozart III\",\n",
    "    \"Am Akkonplatz\",\n",
    "    \"Berliner Flair in Friedrichshain\",\n",
    "    \"DFI Zukunftspark Oberfranken VI\",\n",
    "    \"DFI Zukunftspark Oberfranken IV\",\n",
    "    \"Tonhallen-Passage II\"\n",
    "]\n",
    "\n",
    "projects = sorted(projects, reverse=True)\n",
    "print(projects)\n",
    "\n",
    "# User's question\n",
    "# question = \"Was ist der Zinssatz für das Projekt The Five?\"\n",
    "question = (\n",
    "    \"Hallo, \"\n",
    "    \"ich habe eine Frage zu den Zinsen für das Projekt X\"\n",
    "    \"Könnten Sie mir bitte den aktuellen Zinssatz nennen? \"\n",
    "    \"Vielen Dank und viele Grüße, \"\n",
    "    \"Max Mustermann\"\n",
    "\n",
    "    \"Hallo, \"\n",
    "    \"ich habe eine Frage zu den Zinsen für das Projekt Y. \"\n",
    "    \"Könnten Sie mir bitte den aktuellen Zinssatz nennen? \"\n",
    "    \"Vielen Dank und viele Grüße, \"\n",
    "    \"Max Mustermann\"\n",
    "\n",
    "    \"Hallo, \"\n",
    "    \"ich habe eine Frage zu den Zinsen für das DFI Zukunftspark Oberfranken VI. \"\n",
    "    \"Könnten Sie mir bitte den aktuellen Zinssatz nennen? \"\n",
    "    \"Vielen Dank und viele Grüße, \"\n",
    "    \"Max Mustermann\"\n",
    ")\n",
    "\n",
    "\n",
    "# Step 1: Try to identify named entities\n",
    "entities = ner(question)\n",
    "\n",
    "# Step 2: First attempt exact matching\n",
    "matched_projects = [project for project in projects if project.lower() in question.lower()]\n",
    "\n",
    "if matched_projects:\n",
    "    project_name = matched_projects[0]\n",
    "    confidence = 100  # Exact match, so confidence is 100%\n",
    "else:\n",
    "    # Step 3: If no exact match, fall back to fuzzy matching\n",
    "    project_name, confidence = process.extractOne(question, projects)\n",
    "\n",
    "# Combine results\n",
    "print(f\"Entities found: {entities}\")\n",
    "print(f\"Fuzzy Matched Project: {project_name} with confidence: {confidence}\")\n",
    "\n",
    "# Step 4: Use the project name to query the database\n",
    "# query_database(project_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The approach below is used cosine similarity and looks promising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Similarity: 0.31990915536880493\n",
      "Extracted Project Name: DFI Zukunftspark Oberfranken III\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "model_name = \"sentence-transformers/distiluse-base-multilingual-cased-v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# List of predefined project names\n",
    "project_names = [\n",
    "    \"Projekt Mozart II\", \"Projekt Mozart I\", \"The Five\", \n",
    "    \"DFI Zukunftspark Oberfranken IV\", \"Berliner Flair in Friedrichshain II\", \n",
    "    \"DFI Zukunftspark Oberfranken V\", \"DFI Zukunftspark Oberfranken III\", \n",
    "    \"Am Akkonplatz\", \"Berliner Flair in Friedrichshain\", \"Projekt Mozart III\", \n",
    "    \"Tonhallen-Passage II\"\n",
    "]\n",
    "\n",
    "# Example input text\n",
    "expected_text = \"DFI Zukunftspark Oberfranken III\"\n",
    "input_text = (\n",
    "    \"Hallo, ich habe eine Frage zu den Zinsen für das Park Oberfranken 3. \"\n",
    "    \"Ich würde gerne wissen, wie hoch der aktuelle Zinssatz ist. \"\n",
    "    \"Könnten Sie mir bitte den aktuellen Zinssatz nennen? \"\n",
    "    \"Vielen Dank und viele Grüße, Max Mustermann\"\n",
    ")\n",
    "\n",
    "# Tokenization function\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze()\n",
    "\n",
    "# Get embeddings for the input text\n",
    "input_embedding = get_embeddings(input_text)\n",
    "\n",
    "# Get embeddings for each project name\n",
    "project_embeddings = [get_embeddings(name) for name in project_names]\n",
    "\n",
    "# Compute cosine similarities between input text and each project name\n",
    "similarities = [cosine_similarity(input_embedding.unsqueeze(0), proj_emb.unsqueeze(0)).item() for proj_emb in project_embeddings]\n",
    "\n",
    "print(f\"Max Similarity: {max(similarities)}\")\n",
    "\n",
    "# Find the most similar project name\n",
    "best_match_index = similarities.index(max(similarities))\n",
    "best_project_name = project_names[best_match_index]\n",
    "\n",
    "# Output the result\n",
    "print(f\"Extracted Project Name: {best_project_name}\")\n",
    "assert best_project_name == expected_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the model and tokenizer for German BERT (gbert-base)\n",
    "model_name = \"deepset/gbert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# List of predefined project names\n",
    "project_names = [\n",
    "    \"Projekt Mozart II\", \"Projekt Mozart I\", \"The Five\", \n",
    "    \"DFI Zukunftspark Oberfranken IV\", \"Berliner Flair in Friedrichshain II\", \n",
    "    \"DFI Zukunftspark Oberfranken V\", \"DFI Zukunftspark Oberfranken III\", \n",
    "    \"Am Akkonplatz\", \"Berliner Flair in Friedrichshain\", \"Projekt Mozart III\", \n",
    "    \"Tonhallen-Passage II\"\n",
    "]\n",
    "\n",
    "# Example input text\n",
    "input_text = \"Hallo, ich habe eine Frage zu den Zinsen für das Projekt Mozart III. Könnten Sie mir bitte den aktuellen Zinssatz nennen? Vielen Dank und viele Grüße, Max Mustermann\"\n",
    "\n",
    "# Tokenization function\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze()\n",
    "\n",
    "# Get embeddings for the input text\n",
    "input_embedding = get_embeddings(input_text)\n",
    "\n",
    "# Get embeddings for each project name\n",
    "project_embeddings = [get_embeddings(name) for name in project_names]\n",
    "\n",
    "# Compute cosine similarities between input text and each project name\n",
    "similarities = [cosine_similarity(input_embedding.unsqueeze(0), proj_emb.unsqueeze(0)).item() for proj_emb in project_embeddings]\n",
    "\n",
    "# Find the most similar project name\n",
    "best_match_index = similarities.index(max(similarities))\n",
    "best_project_name = project_names[best_match_index]\n",
    "\n",
    "# Output the result\n",
    "print(f\"Extracted Project Name: {best_project_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Project Name Match: ('Projekt Mozart III', 86)\n",
      "Best Project Name Match: ('DFI Zukunftspark Oberfranken V', 86)\n",
      "Best Project Name Match: ('DFI Zukunftspark Oberfranken III', 86)\n",
      "Best Project Name Match: ('DFI Zukunftspark Oberfranken III', 86)\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import process\n",
    "\n",
    "# List of predefined project names\n",
    "project_names = [\n",
    "    \"Projekt Mozart II\", \"Projekt Mozart I\", \"The Five\", \n",
    "    \"DFI Zukunftspark Oberfranken IV\", \"Berliner Flair in Friedrichshain II\", \n",
    "    \"DFI Zukunftspark Oberfranken V\", \"DFI Zukunftspark Oberfranken III\", \n",
    "    \"Am Akkonplatz\", \"Berliner Flair in Friedrichshain\", \"Projekt Mozart III\", \n",
    "    \"Tonhallen-Passage II\"\n",
    "]\n",
    "project_names = sorted(project_names, reverse=True)\n",
    "\n",
    "# Test 1\n",
    "input_text = \"Hallo, ich habe eine Frage zu den Zinsen für das Projekt Musik III.\"\n",
    "\n",
    "# Extract potential project name from the text (fuzzy matching)\n",
    "best_match = process.extractOne(input_text, project_names)\n",
    "\n",
    "# Print the best match\n",
    "print(f\"Best Project Name Match: {best_match}\")\n",
    "\n",
    "# Test 2\n",
    "input_text = \"Hallo, ich habe eine Frage zu den Zinsen für das DFI Park Oberfranken V. Könnten Sie mir bitte den aktuellen Zinssatz nennen? Vielen Dank und viele Grüße, Max Mustermann\"\n",
    "best_match = process.extractOne(input_text, project_names)\n",
    "\n",
    "# Print the best match\n",
    "print(f\"Best Project Name Match: {best_match}\")\n",
    "\n",
    "# Test 3\n",
    "input_text = \"Hallo, ich habe eine Frage zu den Zinsen für das Projekt Musik III. Könnten Sie mir bitte den aktuellen Zinssatz nennen? Vielen Dank und viele Grüße, Max Mustermann\"\n",
    "best_match = process.extractOne(input_text, project_names)\n",
    "\n",
    "# Print the best match\n",
    "print(f\"Best Project Name Match: {best_match}\")\n",
    "\n",
    "# Test 4\n",
    "input_text = \"Hallo, ich habe eine Frage zu den Zinsen für das Unterfranken III. Könnten Sie mir bitte den aktuellen Zinssatz nennen? Vielen Dank und viele Grüße, Max Mustermann\"\n",
    "best_match = process.extractOne(input_text, project_names)\n",
    "\n",
    "# Print the best match\n",
    "print(f\"Best Project Name Match: {best_match}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
