# Extends a base configuration with the services to launch the test environment.
services:
  app:
    build:
      context: .
      dockerfile: ./smart_mail/Dockerfile
    volumes:
      - ${USERPROFILE}/.aws/credentials:/root/.aws/credentials:ro
    environment:
      - USE_LOCAL_LLM=true
      - LOCAL_LLM_URL=http://ollama:11434/api/generate
      - LOCAL_LLM_MODEL_NAME=marco/em_german_mistral_v01
    depends_on:
      - ollama

  ollama:
    build:
      context: .
      dockerfile: Dockerfile.ollama
    ports:
      - 11434:11434
    environment:
      - OLLAMA_USE_CPU=1
